\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\begin{document}
\section{Popular Methods}
March Madness prediction draws the attention of sport analysts and medias: notably, Nate Silver, Ken Pomeroy and the ESPN. In this section, we will compare these three models against Kaggle entries and examine the ``luck'' factor of Kaggle competition.

Because Silver and Pomeroy published probabilities of each team advancing, our first comparison focused on first round games (round of 64). 
  
We first notice that all three models concurred in win-loss predictions except one (Gonzaga vs OKST, 8 vs 9 in West). All three models have a similar pattern based on the predictions' deviation from 0.5. While most predictions either suggest a easy win (prediction close to 1) or a close game (prediction close to 0.5), predictions around 0.75 are relatively rare in all three models.

In addition, Silver's predictions adapted a more aggressive style than the other two. His predictions, on average, have the highest deviation from 50-50 prediction and Pomeroy averages the lowest. But the differences in style seems to be irrelevant to their scores. For the first around games, Pomeroy has the best score of 0.4632, followed by Silver 0.4664 and ESPN 0.4709. These scores ranked 38th, 45th and 64th respectively, among 433 Kaggle entries. 

We also computed a full-scale team-to-team prediction based on marginal advancement probabilities and found the average score and ranking of all three have dropped markedly from first round: ESPN (0.5795, 88th), Silver(0.5988, 123rd) and Pomeroy (0.6278, 174th). 

Another interesting finding of our comparison is the ``luck'' factor. What if a close game finished differently? To that end, we flipped five overtime games in the first round and noticed a completely reverse of the ranking: ESPN(0.4631, 11th), Silver(0.5025,117th) and Pomeroy (0.5027,120th). This phenomenon is also observed in other Kaggle entries as well. A Kendall's Tau of 0.7169 is measured between the rankings before and after flipping. 

To sum up, popular models exhibit similarities in many aspects but none has shown clear advantages over the majority of Kaggle entries. 
 

\end{document}
